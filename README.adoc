= λRPC

Simple native RPC with high order functions support.

> Inspired by https://github.com/altavir[@altavir] and https://github.com/mipt-npm/communicator[Communicator].

λRPC allows using code with high-order functions as a service.

== Example

Let's suppose that we have a code that loads data and fits a machine learning model.
It also calls a given function on each epoch and continues fitting while it returns true.

[source,kotlin]
----
@Serializable
data class Model(...)

typealias DataLoader = suspend () -> Data

suspend fun fit(
    model: Model, loader: DataLoader,
    continueFitting: suspend (Epoch, Loss) -> Boolean
): Weights
----

To transform the code to a service just add a facade declaration and a `main` function:

[source,kotlin]
----
val conf = Configuration(mlServiceId)
val loader = f(j<Data>()) // Coder for the function: suspend () -> Data
val fit by conf.def(
    j<Model>(), loader, f(j<Epoch>(), j<Loss>(), j<Boolean>()),
    j<Weights>()
)

fun main() {
    val service = LibService(mlServiceId, mlEndpoint) {
        fit of ::fit // Bind declaration and implementation
    }
    service.start()
    service.awaitTermination()
}
----

To make calls from the client, add a `ServiceDispatcher` to the coroutine context and just invoke the declaration:

[source,kotlin]
----
val serviceDispatcher = ServiceDispatcher(
    mlServiceId to mlEndpoint, // Endpoint of the service with GPU for fitting
    dataServiceId to dataEndpoint // Service that provides the data
)

fun main() = runBlocking(serviceDispatcher) {
    // Keep track of the loss function values
    val history = mutableListOf<Loss>()
    var lastEpoch = 0
    val model = Model(...)
    // Bind dataloader with its endpoint, so fit will communicate directly
    // with the service on the dataEndpoint
    val loader = bf(dataloaders.loader)
    val weights = fit(model, loader) { epoch, loss ->
        // Lambda will be executed on the client site
        println("Epoch = $epoch, loss = $loss")
        val continueFitting = if (epoch < 300) true else {
            val max = history.takeLast(50).max()
            loss < max
        }
        lastEpoch = epoch
        history += loss
        continueFitting
    }
    println("Learning finished! Epoch = $lastEpoch, loss = ${history.last()}")
    weights.save(path)
}
----

λRPC does not serialize lambdas and execute them on the client site.
Thus, closures can be passed even to the services written in other languages.

.For instance, for this code, the call diagram is the following:
[source,kotlin]
----
// Service
suspend fun f(g: suspend (Int) -> Int) = g(5) + 1

// Client
val m = 36
f { it + m }
----

image::https://user-images.githubusercontent.com/25281147/153264790-74784fb7-3be6-44a9-a4cf-aa80bb706306.png[]

== Service as a library

λRPC does not use standalone declarations to generate code (native).
It uses library-specific data structures and default or custom serializers instead.

Functions can receive and return other functions as first-class objects.
Provided lambdas are executed on the client side,
so they can easily capture state and be "sent" to the other language process.

All of it makes multi-process communication smooth enough to recognize remote service just as a common library.

== Service-decomposition purposes

- Code execution in different containers or on various hardware (GPU for instance).
- Parallel execution of independent tasks.
- Communication with code written in other languages.
- Rerun subtasks in case of failures or resume them using some state snapshot.
- Run tasks that live longer then single process.
- Microservice architecture.

== Some high order functions (HOF) possible use-cases

* Communication protocol simplification:
** Service function can easily request additional information in some cases.
** Reduce service code duplication: make HOF and receive specific operations from the client.
* Interactive computations: receive client lambda, provide information about computation (loss function value for
  instance), and lambda cancels computation (machine learning process) if something is not good.
* Security:
** Send closures operating on the sensitive data instead of the data itself.
** Provide computational resources as a library of functions that are parametrized by client lambdas instead of
   receiving client's code and executing it.
* Choose dynamically computation location: compute something that uses a large amount of data on a client or send data to the server and
  compute there.
* Load balancing: task is done, request new via client's lambda.
* Stateful streaming computations: nodes provide theirs lambdas for a mapper.

== λRPC functions

.λRPC functions consist of two parts: backend and frontend.
* The backend part contains the programming language closure and serializers
(coders) for the arguments and for the result types.
* The frontend one is a callable proxy object that communicates
with its backend part on call and awaits for the result.

Frontend functions can be sent to other services and λRPC provides
efficient communication with the corresponding backend parts.

== Getting started

.Run both `:detekt` and `:test` tasks
[source,bash]
----
$ ./gradlew :lambdarpc:check
----

.Generate documentation
[source,bash]
----
$ ./gradlew :lambdarpc:dokkaHtml
$ cd ./lambdarpc/build/dokka/html
----

=== Repository organization

.examples
* `basic` -- examples that demonstrate usage of basic λRPC functionality.
[sources,bash]
----
$ cd LambdaRPC.kt
$ ./gradlew :examples:basic.service1
$ ./gradlew :examples:basic.service2
$ ./gradlew :examples:basic.client  # or :examples:basic.stress
----
* `lazy` -- interesting example that shows possibility to build lazy
data processing pipelines using common λRPC functionality.
[sources,bash]
----
$ cd LambdaRPC.kt
$ ./gradlew :examples:lazy.service --args=8090
$ ./gradlew :examples:lazy.service --args=8091
# Any number of services on different ports
$ ./gradlew :examples:lazy.client --args='8090 8091' # Ports of all services
----

.lambdarpc
* `dsl` -- domain-specific language for λRPC library users.
* `exceptions` -- base λRPC exception classes.
* `functions` -- λRPC functions: backend and frontend parts.
* `coders` -- data coder (serializer) and function coder.
** λRPC provides some default data coders based on `kotlinx.serialization`, but users can also implement thier own.
** Function encoding saves language closure as backend function to the registry with some `access name`.
Function decoding creates frontend function that is able to communicate with the corresponding backend function.
* `service` -- libservice implementation.
* `transport` -- service and connection interfaces, extensions and implementations related to the gRPC backend.
* `utils` -- some useful utils.

== Links

* See more information in https://github.com/winter-yuki/LambdaRPC.kt/tree/main/docs[docs].
* Basic Julia lang https://github.com/winter-yuki/LambdaRPC.jl[prototype].
